{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.\n",
    "### a.\n",
    "_Exercise: Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized `Example` protobuf with two features: the serialized image (use `tf.io.serialize_tensor()` to serialize each image), and the label. Note: for large images, you could use `tf.io.encode_jpeg()` instead. This would save a lot of space, but it would lose a bit of image quality._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 21:48:27.709262: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/Adit/codes/ml_101/handson-ml2/ml_env/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.train import BytesList, FloatList, Int64List\n",
    "#from tensorflow.train import Feature, Features, Example\n",
    "BytesList = tf.train.BytesList\n",
    "FloatList = tf.train.FloatList\n",
    "Int64List = tf.train.Int64List\n",
    "Feature = tf.train.Feature\n",
    "Features = tf.train.Features\n",
    "Example = tf.train.Example\n",
    "\n",
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    #image_data = tf.io.encode_jpeg(image[..., np.newaxis])\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label])),\n",
    "            }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function saves a given dataset to a set of TFRecord files. The examples are written to the files in a round-robin fashion. To do this, we enumerate all the examples using the `dataset.enumerate()` method, and we compute `index % n_shards` to decide which file to write to. We use the standard `contextlib.ExitStack` class to make sure that all writers are properly closed whether or not an I/O error occurs while writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\"{}.tfrecord-{:05d}-of-{:05}\".format(name, index, n_shards)\n",
    "             for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                  for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 21:49:40.145872: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-01-11 21:50:17.022985: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-01-11 21:50:20.550025: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    }
   ],
   "source": [
    "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: Then use tf.data to create an efficient dataset for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    #image = tf.io.decode_jpeg(example[\"image\"])\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                  n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                      num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "test_set = mnist_dataset(test_filepaths)\n",
    "valid_set = mnist_dataset(valid_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAB/CAYAAACQeNq9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgUElEQVR4nO2deZBV1fW2FwJCk7YTBhlF5nlQQhhFECUNkkIkqBQhKSAUoTOiVZYJqZAQUsQQYhJCVUgRI6GsoAaiCJYBQtIUKKNMMhmmQGQQwagRRLDxfH/8wvqec+jdXHq6fbvfp8qql9P3nrvv2Wfve3zX3mtVi6IoMiGEEEJUaW5IdwOEEEIIkX70QCCEEEIIPRAIIYQQQg8EQgghhDA9EAghhBDC9EAghBBCCNMDgRBCCCFMDwRCCCGEMD0QCCGEEML0QCCEEEIIq0QPBBcvXrTvfve71rRpU8vKyrI+ffrY3/72t3Q3S5jZ9u3b7b777rN69epZnTp1rGvXrvab3/wm3c2q0qxdu9aqVatW6H+bNm1Kd/OqNBMmTAj2TbVq1ezEiRPpbmKVZdu2bTZs2DDLycmxm266yXJzc23nzp3pblapUSPdDSgtJkyYYEuXLrWHH37Y2rVrZ3/84x9t+PDhlp+fbwMGDEh386osq1evthEjRliPHj1s+vTplp2dbYcPH7bjx4+nu2nCzL7zne9Yr169Ysfatm2bptYIM7MpU6bYkCFDYseiKLK8vDxr2bKlNWvWLE0tq9ps377dBgwYYM2bN7cf/ehH9sknn9hvf/tbGzRokG3ZssU6dOiQ7iaWnKgSsHnz5sjMojlz5vixCxcuRG3atIn69euXxpZVbd5///2oUaNG0ahRo6LLly+nuzkC5OfnR2YWLVmyJN1NESmwfv36yMyiWbNmpbspVZbhw4dHdevWjc6ePevHTp48GWVnZ0df/OIX09iy0qNShAyWLl1q1atXt6997Wt+rHbt2jZp0iTbuHGjvfnmm2lsXdVl8eLFdvr0aZs1a5bdcMMNdv78efvkk0/S3SyR4IMPPrCCgoJ0N0MUweLFi61atWr2pS99Kd1NqbKsX7/ehgwZYvXr1/djTZo0sUGDBtlLL71k586dS2PrSodK8UCwY8cOa9++veXk5MSO9+7d28ysUsV4Mok1a9ZYTk6OnThxwjp06GDZ2dmWk5NjX//61+2jjz5Kd/OEmU2cONFycnKsdu3aNnjwYHvttdfS3SSR4OOPP7Y///nP1r9/f2vZsmW6m1NluXjxomVlZV11vE6dOnbp0iXbs2dPGlpVulSKNQSnTp2yJk2aXHX8yrGTJ0+Wd5OEmR08eNAKCgps5MiRNmnSJHv88cdt7dq1Nm/ePHvvvffsmWeeSXcTqyw33nijjR492oYPH24NGjSwffv22S9+8Qu78847bcOGDdajR490N1H8j1WrVtk777xj48aNS3dTqjQdOnSwTZs22eXLl6169epmZnbp0iXbvHmzmVnlWOyZ7phFadC6devo3nvvver44cOHIzOLfvWrX5V/o0TUunXryMyivLy82PEpU6ZEZhYdOHAgTS0ThXHw4MEoKysrGjp0aLqbIsDYsWOjmjVrxmLXovyZP39+ZGbR+PHjo71790a7d++OxowZE9WsWTMys+jpp59OdxNLTKUIGWRlZdnFixevOn7Fli7M5hFlz5XrPnbs2NjxK3HQjRs3lnubRJi2bdvayJEjLT8/3y5fvpzu5ggzO3funL344os2dOjQWOxalD95eXn2/e9/3xYvXmxdunSxbt262eHDh+2xxx4zM7Ps7Ow0t7DkVIoHgiZNmtipU6euOn7lWNOmTcu7ScL+/3Vv1KhR7HjDhg3NzOzdd98t9zaJomnevLldunTJzp8/n+6mCDNbtmyZffjhhwoXVBBmzZplp0+ftvXr19vrr79uW7du9YXS7du3T3PrSk6leCC4/fbb7cCBA/bf//43dvxKbOf2229PQ6tEz549zezq2NqVNR0333xzubdJFM2RI0esdu3aleL/dioDf/rTnyw7O9vuu+++dDdF/I+6devagAEDrFu3bmb2f4unb7nlFuvYsWOaW1ZyKsUDwQMPPGCXL1+2BQsW+LGLFy/awoULrU+fPta8efM0tq7q8tBDD5mZ2R/+8IfY8SeffNJq1Khhd911VxpaJczMzpw5c9WxXbt22fLlyy03N9duuKFSTA0ZzZkzZ2zNmjU2atQoq1OnTrqbIwrhueees61bt9rDDz9cKcZMpdhl0KdPH3vwwQdt2rRp9vbbb1vbtm1t0aJFdvTo0at+jET50aNHD/vqV79qTz31lBUUFNigQYNs7dq1tmTJEps2bZpCOWlkzJgxlpWVZf3797eGDRvavn37bMGCBVanTh372c9+lu7mCfu/H5uCggKFCyoI69ats5kzZ1pubq7Vr1/fNm3aZAsXLrRhw4bZ1KlT09280iHdqxpLiwsXLkSPPvpo1Lhx46hWrVpRr169opUrV6a7WVWeS5cuRTNmzIhatGgR1axZM2rbtq12fVQA5s6dG/Xu3TuqV69eVKNGjahJkybRl7/85ejgwYPpbpr4H3379o0aNmwYFRQUpLspIoqiQ4cORbm5uVGDBg2iWrVqRR07dowef/zx6OLFi+luWqlRLYqiKN0PJUIIIYRIL5kf9BBCCCFEidEDgRBCCCH0QCCEEEIIPRAIIYQQwvRAIIQQQgjTA4EQQgghLA2JibjLMVlApUaNipsnKdlWZqWqVq1aeTenzEnuRq1o37Go3bIVra1VlWQq8Q8++MA1i5G1bt263NokREkoKChwXRF/r67UVTCzYmVOlEMghBBCCD0QCCGEECINIQPauUVZLrQXV6xY4frJJ590PXHiRNe5ubmu69Wr5/rSpUuud+zY4Xr27NmuR44c6Xrs2LGuP/WpT7muXr16sK2VkVRt906dOrn+8MMPXX/ve99zPXr0aNe0+p955hnXjzzyiOt58+a5/ta3vnXN9iXDOVWtryoqe/fujf2bFuaFCxdcK2QgKjKcs0K/WS+88IJr/l6xiBjPw7mSv1HJ87ds2dI1q/Z+9rOfdT1w4EDXJS2wJIdACCGEEHogEEIIIYRZWosbvfjii7F/00Z5+eWXXWdlZblevXq16xMnTriuW7eua1r9XM3MMARtZlrad999t+vt27e7Hj58eKyttGn4eSVd5VlROHnyZOzfr732mmuWxz106JDrm266yTWtr0GDBrn+6KOPXK9bt841b0OGfPLy8lx37tzZ9Z133pnCtxBlBccV75X333/fNa1QM7Mbb7zRNe+Prl27lkUThSg2nI9C4dOHHnrI9a5duwp9L3clMJTJ3wa+Phnu5JhhmK1+/fqu8/PzXdeuXdt1cX6LMvcXSwghhBClhh4IhBBCCFH+IYNf/vKXrpMhA+4aILRs9uzZ43r58uWuQys1a9as6bpWrVqu27Zt67p///6uT58+7ZorPJMW+u7du11zhWkms3HjRtc///nPY39r0aKFa1r63PXB0AmvL+3lOnXquOa13rdvn+sRI0a4vuOOO1y/+uqrrhlGmjNnTqytn/nMZ1xXlhBOecIp4dixY65PnTrlmuE3kpOT45p2aRKOy169erlWH4nyJBQaSCVkMHjwYNe08znn8Dh/lzh/8Z5P7pjiOPn4449dN2nSxPXzzz9faPuKg0afEEIIIfRAIIQQQohySky0detW17TaaQ2bmTVr1sw1dxzQiqZtMnnyZNfLli1z/c4777hmmKBLly6uO3bs6Pr8+fOus7OzXdMapxVqFt+BsG3bNtc9e/a0TIXhnPbt28f+xgRE586dc017nv13+PBh140aNXJNO40raHndGKph//Xp06fQ8zNsYWb26KOPupYFHYZjiSGbN99803VoZwCtTR7nmLn11ltjn/f666+7pmUqREUjlZAB50HOaxxXnH94nOOHYYHkLgOOE4bpzp49W/QXKCaaLYUQQgihBwIhhBBClFPIgKvMmY85acVwFTkT2HCFO+1MrrRk+IBlV/kZDCXwvf/+979d0/Lk8QMHDsTaev/997tev36960wLGXDlOG0sJrgwMzt69KhrJoFirQFaWtxNMGPGDNdMLsQ+C1lu3N3B0FHz5s1ds0aFuBr2Ky3MUDIVhmzeffdd1wzfdOjQwTVDRUXB9zPMwHsw1XMJURqEwgGhMfP222+7PnLkiOt27dq5DoUb+LvE35mi4FxIuHuhNJFDIIQQQgg9EAghhBCinEIGDAUw1/mnP/3p2Ou4Yp02InccMIkQ8+vTruZKTVorPD+tH1rgtEuZqKdp06axtrKsJc/Lz8uEldT8HrRxedzMrFWrVq5ppzEhFC1hlrRlmIgrammbsVRuKGkHExnxPMkEOGz7zTffbFWd/fv3u/7nP//pmn3KEBFtzh49erjmDpziwDAgx0woyZEQ6SKUr49hZM6D1Bw/nLN4nCFSzmXc1ZM8L2EYvjSRQyCEEEIIPRAIIYQQogxDBiyLyxXqTPCTtAppKdL2Z+Ig2sF8De2YUP5nWtp8PfO104phW//1r3/F2korm+3gboTbbrvNKjrsG14fWrpmZv/5z39cs/QmE2Rw5wZDMrT0GSaiHcYdBAxD0Frja3jvsOyyWdymq6ohA46T9957r9Dj3bt3d81wAPsxFRjSY8KopK3JccL+o03KUOH1tkOIsobzJXc6hcIH1A0bNnTN3w+GajnfmcVDF6EkR6WJHAIhhBBC6IFACCGEEHogEEIIIYSV4RoCFn7gtj7GPjZs2BB7D4uhMP7OuCdjlKE60lxzQLi2gOsGuJ6A7Wb8hkWZzOI13IvarlfR4VoPxniTW8y4hoJrDRgXY8yY8X7CtQWMPTOmzOM8J9eYcMviW2+9FfuMPXv2uO7atWuh7ajshLZoDhw40DW3dzIjYSh2z0xrBw8edM0xzbHE+8QsXGiKWx55f/DeShZ9yQRSKZBDOIeFvu+qVatccwvc8OHDXT/xxBOuWbAs1LZk+7jmhGt+UvkOlYXk9r8rMFMu10ZxvuPW81tuucV1qLhRaGuhWXhbN8c3z8uxzvUIqRZ5k0MghBBCCD0QCCGEEKIMQwYsnEKrlyS38tEipKVFS4RWGu0RWiu08Hke1nynJcTX8Djbx213ZuHMVLT0hgwZYhUdbvOiDc/a9cm/0WrmtkP2AbctcvsmX89iUwwN0EJm3/M+YugoWYiJtl5Vhfc0t4nS9uf4Yb8cP3680OMM6/C9/CwWtWLWT7N4ZlHeQ8xqyT4+ceKEa4YTM4VQZjoepw6FCX7/+9+75jzELbUrVqxw/cILL7ieNWuWa17zoux/ZrNkyGDlypWuv/nNb7rmvVDZYSE7hlVD4WuOGV5//kYRzqFm8fuGmmEdzqONGzd2XZwQjxwCIYQQQuiBQAghhBBlGDLgSmXWjabVm1zJ3qlTJ9epFILga1JZRUlrma+nXc0VonfffbfrhQsXxs7VsWNH1/369XN9zz33XLMdFQl+X/ZHMkRy8uRJ1yyKQ+uKlietae4aoCUWKkLF/mafhbIZ0qY2C4eoKju8Jhwb7Ff2FwuNcbyGdpQwIyTHD0N9jRo1KrQNZvEsngwjde7cudDzJrO2VUQYLkmu3Od3SWV+oh29bNmyQt8bCitwJ9fcuXNdP/vss64nTpx4zTaYmTVo0MB1mzZtXHPO27lzp2sWL8tkQqvyGbbcsWOHa9733J0W2rHBkAF1sjgb4VzGNjFLIsPU48ePL7QdqSKHQAghhBB6IBBCCCFEGYYMcnNzC9VFQctz2rRprmmT0cKk1UI7JRWrhPYQ7UuuUP/GN77hOlQfO9PhClXaWMmV+2+88YZrWtBMvMHQS6jwFG1qhn8YDmCIgW2iLcfdIMniRtplEF/FzGvLccJV/Ay7sE9DiYKaNm163W3atGmT63HjxhX6GbxXikrYUlI4/kNjO1RYhsdD93lRcAfWP/7xD9dMasYdBAzf0c5v376960WLFrlmwiKGaH/84x+7ThZe4/hm6IIJq7Zt2+aauxoYoshk+HvC+YU7bUKhTd4HnAc5f3G+41wWSnBkFp+HmXCPY+PXv/61a4YMioMcAiGEEELogUAIIYQQZRgyoA0SSsKQhLYcEzowOUYoAUQoGVEIvpfnp/VDC482aqrnraj510PJaWhP0dIyi1uMtEYZ5uG52P+8vgz5cAUtExkRhgNo17FvGPJJcr355DMNXv/QbhyOJV43rlSmLc0+4jW73hrsydXTobAErVCO79A9URqkmtv9WvA7JscM7eLf/e53rhky4A4l7uRhciDuIKCePHmya1rcXNnOWh4M+WzevDnWVo6zvLy8Qr8TrXDuJinOXF8RCc3X+fn5rjneGNbhnMp7i3MTr18o7JSsw8N/s48ZWti/f79rhn64KyRV5BAIIYQQQg8EQgghhCjDkEHIOirKwqXVQhsq1SQOVwglNKE1Q/uTNhBt86JydIeSWFTUMAHhqln2E69t8hq2a9fONe0x2vjsTx7navbQym1a1uwbtoO58dlWWuLJdvBvRYUWMhXeu+yXUO581jVg0hlaxkePHnVNy5i7N3jfNGvWrNC2cYW6mdm3v/1t17RC2VbuQklHf7GGx/Lly10zfEFrn2EQJjIziydk41zyyCOPuJ45c6Zr9sEXvvAF19x1wzAbr+eSJUtcf/7zn3fNHV6DBw92/ZOf/CTWVn4nfgbvL9rUfA3vkbIM85Q1obl78eLFrhlm41zG+5n1YTg2GDLgTi1eP86bZuHfIM6dnBenT5/umvdEqsghEEIIIYQeCIQQQghRhiGDEKmGDELWcmhVe6gccWjHAW3K0DmTyXlC7y+tFcvlBa1cWlRcnZz8Try+oaROtDZDdm+ob7iCNlTymDY1V8IzpGQWDz9wtXavXr0KbVMmQ4udK9AZGmBtAvYjdxzQrqYFyRXxtIN5Tq62DiU7Mov3d6jeBMccv09p88orr7jevXu3a96HvJ+ZPIn3IeuvHDp0KPYZnEt4HdesWeN6wIABrhneYsIiJiMK1RCgVcw+YPnj2bNnu06Oz1CNkVBOf2qOt0wLGfB7hOx59h1DAFzRz/uGu6p4bXg8NBaSvzk8L8duaK7lfXPs2DHXLVq0sFTIrF8yIYQQQpQJeiAQQgghRPmHDIqCK8dpLdOio71Ci6eoMqSFEQo38LMyOclGUdBm5ncP5co2i9u3vC6p7OigpcXjoX7lqttQ6IF9TIvULG7NZWop5FBojTsJkq+jRU/7mfYiyxwzNz1DDLx+DCUwR369evVcb9mypdDzc3W2WTxEwbBEt27dXF9vgrHiwroKoWRZTJ4USpjE1fnJ3S68d2kdc57jNW3cuLFr9gHHGPvp6aefds1r2Lt3b9e8zryeRSVR4jUI1ZPgOGa4IdMIhQlYGyJUY4K7BnhPhHYQ8LN4jTnGeC+axa8t+yIUzmYIhHUsFDIQQgghRMrogUAIIYQQFStkQBuFtgutGdouIbs6FAIgtM/4en5W6PyZDkMGtKhoTyVLCtM+ZeIaJivhteO5uHuB/UcrnKtpCfsmZJnx+5jFv1Pyb5lO0lKkRc97mv3HcA+vR4cOHVyvXr3a9YMPPui6devWrmmJ0/Zmshbm7O/cuXOsrUzIQ6v9+eefd923b1/XoXuiNBgzZozr+fPnu2ayJt63tPY5p3AHAO18s/h8du+997rm92K4i6XIeX2pmSCM51mwYIFrzp1s68svv+w6uRsgFBLh96Md/cADD7guTs78siDVuiWpvI4lhbt37+6a810orM3+4nwXKuuealsZEgy1g68pzviRQyCEEEIIPRAIIYQQIs2JiZLQcqYFQ6uF9mco530qcJUsLR6eM7lqmGRyKV1amVw1y1XnPXv2jL2HNiKTGdFSDF0v2ma0umhT0t4KJR2iDc4EHMkVt7yPKsMuA5IMGaTyHq4wZq5+Xk/azKdPn3bNMrd/+ctfXE+ZMsU1LX/m82dO/SRNmzZ1zVBQqonBSgrDHFOnTnXN0Mmtt97qmuEP7vRg6VleN7N4ArBQ6IvzHL8v5zOOMa5av+OOOwrVHNPs4x/84AeuGQoyK1kSKIZWKkpioqLCAqG5+69//atrhkUZpgnV4OBcxjknlPiI8xrDeMm2se+PHz/umvca+5jHi1MLRA6BEEIIIfRAIIQQQogKFjIIJcSgzZxKQoxUaguEbDu2jyuhb7vttuC5Ul3dWlGgjRUqvZncZUBbkLZ1yAplX4ZKENPaZ+IWhoj4GlqhRdmUDAHx3skkUq2Pkcq9x3O1atXKNW1R7iJhmeMVK1YU+t6XXnrJNXc6FBUmCMH7g7ZqedUIYVjkK1/5imvWO2BogHbvPffc45rjyix+v3LMMDTABEQM23CeK4v5JZlwiOOVOyr4eaxfsXLlStfcQVGc/i8tQnVSkt81VOZ4zpw5rnlPcI5k8iheD4YSOOc0bNjQNe+B0BychCGAUGnw0PdRyEAIIYQQxUIPBEIIIYQo/5BBUZYXE3PQNqb1lrTlCiOV0sR8DW1K2i9sT1FkQpiAcJU07Utaa7TDzOJlP0nI4uWqZYZ2QvUSQiWu+RqWoOXqW1qtZuHyrZlEquW1r/feo0UdqivBcAxDCQzNcEU2dxyQ5FgN5Y1PpTZGOmBpYmomE2K++GQimM2bN7sOJRri/R0KK3BnCI+HbGdeQyaqYaiDbUiel+OJ76f9/dOf/rTQ91YUOC5ClrqZ2XPPPed6x44drjlO+P1C9j4/g3Mf73lec/6+nTp1KthW9hkTiTEswXArCc3ZRZGZs6UQQgghShU9EAghhBCifEIGqZYx5erWkIVFeyQVuzT02bRmaLHR9isqZFCUDVXRoQ3Flai06pOWIi00WrzcmcDjIdufdhotUr6Xdhj7g+fs1KmT62RCGPZbppZmDYUJkjY8rUf2USowOc/u3btdMzTQvn1717SJ586de83zp1o+PFSKvKJCK7YoW5ZhBlH2cB6nLuo+nDFjhmv2Jccfk2hxrmHYMjSXHTt2zDUTC/E+546GZPiFZcY5TpJzXmHvD4XoikIOgRBCCCH0QCCEEEKIClb+mAlKaBvTXgmtQg6FAEIr2UOWLC0XrrYuikxLTMQyra+++qprWl1cUWwWT4pBG57XizsIGIrgcdpYTDpEK5yan8VQB19z5syZWFuZVKksS+iWJfx+tBrPnj0bfE+vXr0KPR4KmzHEwN0EXEm9bt061wMHDiz0PBxjHIepjoVMGz+i/AklQOP4TmV+NzMbMWKEa4bcWLuCc8rOnTtdcw7ifctQKOdRtpVh2FGjRrnetWuX62QJbYZkqTmPsh3JUO/1IodACCGEEHogEEIIIYQeCIQQQghh5bSGgHHBVGOEjJEwsx4JZRskoW1MoQxhPCdj38k4bKiQRibEQFnIhLF+1m9Pbtfjvxm34/u55oLHeU1YUKdfv36uuX6EcTDGzdgf3BqX7GNmV+N7KiKheydU6Otzn/tc7P0l2XrL93JtAtePMGPl1KlTr3me4owF3k+pZCIVVQ+uTUlly/eaNWtcP/bYY7G/ces6t/VxrU5oTRPXB4TawbmMhcLWr1/vmlkHOd64lif52aG1AhxnWkMghBBCiBKjBwIhhBBClP+2w6K2g3ALCC1qbkGkpU/LJhQaYCghlJGQVgzPSfvlrbfeip2XNeAzDV5P2uu0+UNhGrO4zcZrRDuN52UmLh6nDmVCpOVPO43hjZMnT8ba1717d9fcJlQRCdnq3DrJzIubNm2KvY59yaxrS5YscR2yNjnGNm7c6JrZCRmaYWiNhEISyS3CoXZwLJbU8hSVE4YOmTGTxaW2bdvmmoXQWrVqFTsXt/bx94hzHm18hgB4D3NeY+ZAZtydPn26a2aufOWVVwptQzJkxt81zmUcu2x3qtlBQ8ghEEIIIYQeCIQQQghRwTIVMnNdyDoM2ZOhbIa0Y/iaUCghFDJgTXKzeMgg1dr1FQVatLTeaY317ds39p4NGza4pqXMMAOtOIYDmPWLFjf7m7Z/mzZtCj0P+49WYTK7F+8Rfr90wrazfalYfAwrTJ48Ofa3EydOuOYuD+4ImDdvnmuueqbVOGzYMNczZ850vWjRomu2LxQKSLWoWSiMJMQVJk2a5Prvf/+761Dxn44dO7pO3p+cj/g3zosMjzF8R6uemuecOHGia44lwt8JtjtZ3IghBGYQ5bzLLLIKGQghhBCixOiBQAghhBDlEzJINVkJbVXaNHxPqLgRSSbVKew8oQQotJBov7Ru3Tr4eZmQjIhw1W3z5s1d89qOHz8+9p4JEya4XrVqlWta/UzsEeoDhglocYeKU9EmGzRokOv9+/e7ZmERM7N27dq5ToYT0sW+fftcM2kKVw7ze9BGZNGV+fPnx87La9WlS5dCj2/ZssU1dyxw5TaTpvzwhz90nUoILDS+Ux0X3EnCUFC3bt1Ser+onBw8eNA1i7BlZ2e7ZoiJcwtX/SfDzxxbDBNwRw2Pc27ie/kZTDT01FNPFfZ1YnBc8bcl+bvE1/F787uGEsUVBzkEQgghhNADgRBCCCHSHDJgTmkzs/z8fNcNGjRwTauE9kgqKyppnfL1tGZob3OlPS3wUOIjs8wLGdB23rt3r+tTp065plVvFt9VMXr06Ov6vGnTpl1vE68Jbba77ror9jeupKelOHTo0FJvR6rQ/qZmAhUmNOHKYSbFSlqKvHd3795d6HEm/OK44jVkspfQzo7Q7ohU7/9QEiuGMZ599lnX999/f0rnFZUTzsVMXEYLn/c266SwFgh/M5L/5m8L5zzenzwXNXdiMbEX4fgJ7WDjbh+G8ZL/5g6t0LlSqfNQFHIIhBBCCKEHAiGEEEKYVYtSzR5SDuzatcv1G2+84ZqrkI8cOeKadhFDAyGbhis2aQlxdTdXajdr1sx1z549g+3OtPLHS5cudf3EE0+45s6O1atXB99f0b5v7969Y/+mLT579mzXWrWeGhxL7F+Oq+IkQMm0BF6iYsLQ5rFjx1wz/EkbnqFfs/juJlryDAcwlMCdQD169HCdl5d3zbaG5kp+h3HjxrnmTgezcKiabeJuh9zcXNfFCdVqVAohhBBCDwRCCCGEqGAhAyGEEEKkBzkEQgghhNADgRBCCCH0QCCEEEII0wOBEEIIIUwPBEIIIYQwPRAIIYQQwvRAIIQQQgjTA4EQQgghTA8EQgghhDCz/wcJanWmCs9i/wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
    "    \n",
    "Standardization = Standardization(input_shape=[28, 28])\n",
    "# or perhaps soon:\n",
    "# standardization = keras.layers.Normalization()\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                               axis=0).astype(np.float32)\n",
    "Standardization.adapt(sample_images)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    Standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10/Unknown - 0s 9ms/step - loss: 0.1908 - accuracy: 0.9406  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 22:00:01.237976: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-01-11 22:00:01.238019: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-01-11 22:00:01.238133: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-01-11 22:00:01.445982: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-01-11 22:00:01.446072: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-01-11 22:00:01.465555: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-01-11 22:00:01.474790: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-01-11 22:00:01.476597: I external/local_tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: ./my_logs/run_20240111_220001/plugins/profile/2024_01_11_22_00_01/ADIT-MBP.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 11s 6ms/step - loss: 23.2232 - accuracy: 0.9127 - val_loss: 298.5380 - val_accuracy: 0.8856\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 115.2830 - accuracy: 0.9183 - val_loss: 145.6849 - val_accuracy: 0.8832\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 64.0264 - accuracy: 0.9234 - val_loss: 26.3603 - val_accuracy: 0.8856\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 89.0251 - accuracy: 0.9276 - val_loss: 119.0893 - val_accuracy: 0.8866\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 14.7069 - accuracy: 0.9307 - val_loss: 265.7299 - val_accuracy: 0.8906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1360ba160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "logs = os.path.join(os.curdir, \"my_logs\",\n",
    "                    \"run_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10)\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
